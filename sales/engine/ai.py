import os
import time
import json
import uuid
import logging
import asyncio
import re
import hashlib
from contextvars import ContextVar
from typing import Optional, Dict, Any, Tuple
from dotenv import load_dotenv

# Dependencias de Alto Rendimiento (pip install pydantic tenacity openai)
from pydantic import BaseModel, Field, ValidationError, ConfigDict
from tenacity import (
    retry, 
    stop_after_attempt, 
    wait_exponential_jitter, 
    retry_if_exception_type,
    before_sleep_log
)
from openai import AsyncOpenAI, RateLimitError, APITimeoutError, APIError, InternalServerError

# =========================================================
# 1. TELEMETR√çA DISTRIBUIDA Y VARIABLES DE CONTEXTO
# =========================================================
load_dotenv()

trace_id_var: ContextVar[str] = ContextVar("trace_id", default="SYS_BOOT")

class TraceInjectingFilter(logging.Filter):
    """Inyecci√≥n de trazabilidad OTel (OpenTelemetry) param√©trica."""
    def filter(self, record):
        record.trace_id = trace_id_var.get()
        return True

logger = logging.getLogger("Sovereign.SingularityEngine")
logger.setLevel(logging.INFO)
if logger.hasHandlers():
    logger.handlers.clear()

handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter('%(asctime)s.%(msecs)03d - [%(levelname)s] [TRACE:%(trace_id)s] - %(message)s', datefmt='%H:%M:%S'))
handler.addFilter(TraceInjectingFilter())
logger.addHandler(handler)

# =========================================================
# 2. L1 QUANTUM CACHE (IDEMPOTENCIA & FINOPS)
# =========================================================
class AsyncL1Cache:
    """
    [SINGULARITY TIER]: Cach√© en memoria RAM de acceso O(1).
    Evita llamadas duplicadas al LLM ahorrando el 100% de los tokens
    y reduciendo la latencia de red a 0ms en peticiones repetidas.
    """
    def __init__(self, ttl_seconds: int = 3600):
        self.ttl = ttl_seconds
        self._cache: Dict[str, Tuple[float, str]] = {}
        self._lock = asyncio.Lock()

    async def get(self, key: str) -> Optional[str]:
        async with self._lock:
            if key in self._cache:
                timestamp, data = self._cache[key]
                if time.time() - timestamp < self.ttl:
                    return data
                del self._cache[key] # Expirado
            return None

    async def set(self, key: str, value: str):
        async with self._lock:
            self._cache[key] = (time.time(), value)

# Instancia global de cach√© (1 hora de TTL)
l1_memory_cache = AsyncL1Cache(ttl_seconds=3600)

# =========================================================
# 3. ADAPTIVE CIRCUIT BREAKER & THROTTLING
# =========================================================
MAX_CONCURRENT_LLM_REQUESTS = 50
llm_throttle_semaphore = asyncio.Semaphore(MAX_CONCURRENT_LLM_REQUESTS)

class AdaptiveCircuitBreaker:
    """
    [SINGULARITY TIER]: Cortocircuito con Auto-Curaci√≥n. 
    Aplica Backoff Exponencial al Cooldown si el LLM sigue ca√≠do.
    """
    def __init__(self, failure_threshold: int = 8, base_cooldown: int = 30):
        self.failure_threshold = failure_threshold
        self.base_cooldown = base_cooldown
        self.current_cooldown = base_cooldown
        self.failures = 0
        self.last_failure_time = 0.0
        self.is_open = False
        self._lock = asyncio.Lock()

    async def record_failure(self):
        async with self._lock:
            self.failures += 1
            self.last_failure_time = time.time()
            if self.failures >= self.failure_threshold:
                if not self.is_open:
                    self.is_open = True
                else:
                    # Penalizaci√≥n exponencial al proveedor si sigue fallando
                    self.current_cooldown = min(self.current_cooldown * 2, 300) 
                logger.critical(f"üö® [CIRCUIT BREAKER] ABIERTO. Cooldown escalado a {self.current_cooldown}s.")

    async def record_success(self):
        async with self._lock:
            if self.is_open or self.failures > 0:
                logger.info("üü¢ [CIRCUIT BREAKER] CERRADO. Conexi√≥n restaurada y estable.")
            self.failures = 0
            self.current_cooldown = self.base_cooldown
            self.is_open = False

    async def check_state(self):
        async with self._lock:
            if self.is_open:
                if time.time() - self.last_failure_time > self.current_cooldown:
                    logger.warning("üü° [CIRCUIT BREAKER] Half-Open: Evaluando recuperaci√≥n...")
                    return True
                raise ConnectionAbortedError(f"Circuit Breaker Fast-Fail (Cooldown activo: {self.current_cooldown}s).")
            return True

deepseek_circuit_breaker = AdaptiveCircuitBreaker()

# =========================================================
# 4. SCHEMAS, CONEXI√ìN & ZERO-TRUST FIREWALL
# =========================================================
class B2BPitchSchema(BaseModel):
    model_config = ConfigDict(strict=True, extra='forbid')
    chain_of_thought: str = Field(description="An√°lisis profundo y razonamiento de c√≥mo persuadir a este rol.")
    psychological_trigger: str = Field(description="Sesgo cognitivo explotado en el copy.")
    subject_line: str = Field(description="Asunto magn√©tico hiper-personalizado.")
    email_body: str = Field(description="El cuerpo del correo B2B. Directo, sin saludos, valor absoluto. M√°ximo 80 palabras.")
    predicted_conversion_score: int = Field(ge=1, le=100)

api_key = os.getenv("DEEPSEEK_API_KEY")
client = AsyncOpenAI(
    api_key=api_key,
    base_url="https://api.deepseek.com",
    max_retries=0, 
    timeout=20.0 
) if api_key else None

def _prompt_armor_sanitization(text: str) -> str:
    """
    [SINGULARITY TIER SEC]: LLM Firewall. 
    Bloquea inyecciones de contexto y neutraliza comandos hostiles.
    """
    if not text: return "Desconocido"
    # 1. Purga de caracteres de formato LLM
    clean_text = re.sub(r'[<>{}|`\\]', '', str(text)).replace('\n', ' ')
    # 2. Heur√≠stica Anti-Jailbreak (Inutiliza vectores de ataque)
    jailbreak_patterns = [r'(?i)ignora', r'(?i)instrucciones', r'(?i)system prompt', r'(?i)olvida']
    for pattern in jailbreak_patterns:
        clean_text = re.sub(pattern, '[REDACTED]', clean_text)
    
    return clean_text.strip()[:100]

def _get_dynamic_pain_point(role: str) -> str:
    role_lower = str(role).lower() if role else ""
    if any(x in role_lower for x in ["rector", "director", "gerente", "ceo"]):
        return "la p√©rdida de competitividad frente a la competencia y el alto costo de adquisici√≥n de alumnos"
    elif any(x in role_lower for x in ["coordinador", "acad√©mico", "profesor"]):
        return "la sobrecarga administrativa y el desgaste docente por uso de herramientas arcaicas"
    elif any(x in role_lower for x in ["tecnolog√≠a", "sistemas", "it", "cto"]):
        return "la deuda t√©cnica inmanejable, costos de servidores inflados y vulnerabilidades en la data estudiantil"
    return "la ineficiencia operativa que drena silenciosamente el presupuesto de la instituci√≥n"

def _generate_cache_key(name: str, role: str, inst: str) -> str:
    """Genera un hash SHA-256 criptogr√°fico para identificar duplicados exactos."""
    raw_key = f"{name.lower()}_{role.lower()}_{inst.lower()}"
    return hashlib.sha256(raw_key.encode('utf-8')).hexdigest()

# =========================================================
# 5. MOTOR DE INFERENCIA SINGULARITY
# =========================================================
@retry(
    stop=stop_after_attempt(4),
    wait=wait_exponential_jitter(initial=2, max=15),
    retry=retry_if_exception_type((RateLimitError, APITimeoutError, InternalServerError, APIError)),
    before_sleep=before_sleep_log(logger, logging.WARNING)
)
async def generate_b2b_email(contact_name: str, contact_role: str, institution_name: str) -> Optional[str]:
    """
    [SINGULARITY TIER ENGINE]
    Motor de generaci√≥n absoluto. Idempotente (L1 Cache), Inmune a Jailbreaks (Prompt Armor),
    Escalabilidad Protegida (Semaphores & Adaptive Circuit Breakers), Telemetr√≠a OTel.
    """
    if not client: return None

    current_trace = uuid.uuid4().hex[:8]
    trace_token = trace_id_var.set(current_trace)

    try:
        # 1. Sanitizaci√≥n de Grado Militar (Firewall)
        s_name = _prompt_armor_sanitization(contact_name)
        s_role = _prompt_armor_sanitization(contact_role)
        s_inst = _prompt_armor_sanitization(institution_name)

        # 2. Comprobaci√≥n L1 Quantum Cache (Ahorro FinOps 100%)
        cache_key = _generate_cache_key(s_name, s_role, s_inst)
        cached_pitch = await l1_memory_cache.get(cache_key)
        if cached_pitch:
            logger.info("‚ö° [L1 CACHE HIT] Resultando servido desde RAM (Latencia: 0.0ms, Costo: $0.00)")
            return cached_pitch

        # 3. Verificaci√≥n de Integridad de Red (Circuit Breaker)
        await deepseek_circuit_breaker.check_state()
        
        pain_point = _get_dynamic_pain_point(s_role)
        system_prompt = (
            "Eres un SDR B2B de √©lite operando en Silicon Valley. "
            "Eres cl√≠nico, letal y odias el relleno. Tu objetivo es agendar llamadas. "
            "Devuelve la respuesta ESTRICTAMENTE en un objeto JSON v√°lido. Nada m√°s."
        )
        user_prompt = f"""
        TARGET: {s_name} | ROL: '{s_role}' | EMPRESA: {s_inst}
        DOLOR PRINCIPAL: {pain_point}
        SOLUCI√ìN A VENDER: "Learning Labs" (Plataforma educativa en la nube)
        
        REGLAS:
        1. Hook: Ataca el dolor principal en 1 l√≠nea.
        2. Soluci√≥n: Destruye el dolor con Learning Labs en 1 l√≠nea.
        3. CTA: Fricci√≥n Cero ("¬øAbierto a hablar 5 min el martes?").
        4. Longitud: Menos de 80 palabras.
        
        JSON KEYS REQUERIDAS: 'chain_of_thought', 'psychological_trigger', 'subject_line', 'email_body', 'predicted_conversion_score'.
        """

        # 4. Adquisici√≥n de Recursos Cr√≠ticos (Sem√°foro de Descriptores)
        async with llm_throttle_semaphore:
            start_time = time.perf_counter()
            logger.info(f"Iniciando Inferencia Cu√°ntica para {s_inst}...")
            
            try:
                # Absolute Timeout Kernel-Level
                async with asyncio.timeout(25.0):
                    response = await client.chat.completions.create(
                        model="deepseek-chat",
                        response_format={"type": "json_object"},
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.4,
                        presence_penalty=0.1, 
                    )
                
                await deepseek_circuit_breaker.record_success()

                raw_json = response.choices[0].message.content.strip()
                parsed_data = B2BPitchSchema.model_validate_json(raw_json)
                
                # Telemetr√≠a OpenTelemetry Mock
                latency_ms = (time.perf_counter() - start_time) * 1000
                metrics_payload = {
                    "event": "llm_inference",
                    "target": s_inst,
                    "latency_ms": round(latency_ms, 2),
                    "tokens": response.usage.total_tokens,
                    "score": parsed_data.predicted_conversion_score
                }
                logger.info(f"FINOPS: {json.dumps(metrics_payload)}")
                
                final_email = parsed_data.email_body
                
                # 5. Escribir en la L1 Cache para futuras peticiones
                await l1_memory_cache.set(cache_key, final_email)
                
                return final_email

            except Exception as e:
                await deepseek_circuit_breaker.record_failure()
                raise e

    except ConnectionAbortedError as cae:
        logger.error(str(cae))
        return None 
    except ValidationError as ve:
        logger.error(f"Hallucinaci√≥n Matem√°tica del LLM. Esquema violado: {str(ve)}")
        return None 
    except Exception as e:
        logger.error(f"[NETWORK FAULT] Fallo cr√≠tico final: {str(e)}")
        return None
    finally:
        trace_id_var.reset(trace_token)