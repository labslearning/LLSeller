import logging
import asyncio
import requests
import uuid
import re
from typing import Dict, List, Any, Optional

from celery import shared_task
from celery.exceptions import SoftTimeLimitExceeded
from requests.exceptions import RequestException, Timeout
from django.core.cache import cache
from django.db import transaction
from django.utils import timezone

# Importaciones locales optimizadas para alta disponibilidad
from .models import Institution
from .engine.serp_resolver import SERPResolverEngine
from .engine.recon_engine import _orchestrate, execute_recon

# Logger de grado industrial con trazabilidad para CloudWatch/Datadog
logger = logging.getLogger("Sovereign.CeleryWorkers")

# =========================================================
# MISI√ìN 0: SINGLE TARGET RECON (MOTOR CON TELEMETR√çA)
# =========================================================
@shared_task(
    bind=True, 
    queue='scraping_queue',
    soft_time_limit=240, 
    time_limit=300,
    name="sales.tasks.task_run_single_recon"
)
def task_run_single_recon(self, inst_id: str):
    """
    Motor quir√∫rgico de √©lite para las Ventanas 1 y 2.
    Implementa un log de telemetr√≠a as√≠ncrono para actualizaci√≥n de UI v√≠a HTMX.
    """
    def log_telemetry(message: str):
        """Helper para inyectar logs en el flujo de la Sniper Console."""
        current_logs = cache.get(f"telemetry_{inst_id}", [])
        timestamp = timezone.now().strftime('%H:%M:%S')
        current_logs.append(f"{timestamp} | {message}")
        # Mantenemos solo los √∫ltimos 10 eventos para optimizar RAM
        cache.set(f"telemetry_{inst_id}", current_logs[-10:], timeout=600)
        logger.info(f"[TELEMETRY][{inst_id}]: {message}")

    log_telemetry("üéØ Objetivo fijado. Iniciando secuencia de aproximaci√≥n...")
    
    # Patr√≥n: Distributed Lock (Evita colisiones por doble clic del usuario)
    lock_id = f"lock_recon_{inst_id}"
    if not cache.add(lock_id, "processing", 600):
        log_telemetry("‚ö†Ô∏è Misi√≥n abortada: El objetivo ya est√° bajo fuego de otro proceso.")
        return f"Skipped: {inst_id} en proceso."

    try:
        log_telemetry("üåê Levantando t√∫neles proxy residenciales y rotaci√≥n de IP...")
        log_telemetry("üïµÔ∏è‚Äç‚ôÇÔ∏è Ejecutando Bypass de WAF (Cloudflare/Akamai)...")
        
        # Ejecuci√≥n del motor forense Ghost Sniper
        execute_recon(inst_id)
        
        log_telemetry("üß† Extrayendo Tech Stack y analizando patrones con IA...")
        log_telemetry("‚úÖ Inteligencia completada. Sincronizando con el n√∫cleo central.")
        return f"Success: Perfil {inst_id} enriquecido."
        
    except Exception as e:
        error_msg = f"‚ùå FALLO CR√çTICO: {str(e)}"
        log_telemetry(error_msg)
        logger.error(f"Falla en misi√≥n {inst_id}: {str(e)}")
        raise
    finally:
        # IMPORTANTE: Liberamos el sem√°foro para que el Polling de HTMX detecte el fin
        cache.delete(f"scan_in_progress_{inst_id}")
        cache.delete(lock_id)


# =========================================================
# MISI√ìN 1: RADAR OPENSTREETMAP (GEO-DISCOVERY MASIVO)
# =========================================================
@shared_task(
    bind=True, 
    queue='discovery_queue', 
    max_retries=3, 
    default_retry_delay=60,
    autoretry_for=(RequestException, Timeout),
    soft_time_limit=600,
    time_limit=660
)
def task_run_osm_radar(self, country: str, city: str, mission_id: Optional[str] = None):
    """
    Motor de Extracci√≥n Geoespacial de alto rendimiento V5.0.
    Utiliza tagging por 'mission_id' para alimentar la Ventana 3 (Geo-Radar).
    Inmune a errores de tildes y may√∫sculas mediante Fuzzy Regex.
    """
    batch_uuid = mission_id or str(uuid.uuid4())
    logger.info(f"üõ∞Ô∏è [OSM RADAR] Desplegando sobre {city}, {country} | Misi√≥n ID: {batch_uuid}")
    
    # üß† Magia de Silicon Valley: Regex Din√°mico para Tildes
    # Transforma "Bogota" en "[bB][oO][gG][oO√≥√ì][tT][aA√°√Å]" para enga√±ar a OSM
    city_fuzzy = re.sub(r'[aA√°√Å]', '[aA√°√Å]', city)
    city_fuzzy = re.sub(r'[eE√©√â]', '[eE√©√â]', city_fuzzy)
    city_fuzzy = re.sub(r'[iI√≠√ç]', '[iI√≠√ç]', city_fuzzy)
    city_fuzzy = re.sub(r'[oO√≥√ì]', '[oO√≥√ì]', city_fuzzy)
    city_fuzzy = re.sub(r'[uU√∫√ö]', '[uU√∫√ö]', city_fuzzy)
    
    query = f"""
    [out:json][timeout:180];
    area["name"~"^{city_fuzzy}$",i]->.searchArea;
    (
      nwr["amenity"~"school|kindergarten|university|college"](area.searchArea);
    );
    out center tags;
    """
    
    try:
        logger.info("üì° [OSM RADAR] Enviando pulso a la API de Overpass...")
        response = requests.post("https://overpass-api.de/api/interpreter", data={'data': query}, timeout=185)
        response.raise_for_status()
        elements = response.json().get('elements', [])
        
        logger.info(f"‚úÖ [OSM RADAR] API Respondi√≥. Nodos crudos detectados por el sat√©lite: {len(elements)}")
        
        if not elements:
            logger.warning(f"‚ö†Ô∏è [OSM RADAR] OSM no tiene datos para '{city}'. Intenta con el nombre oficial de la regi√≥n.")
            return f"Cero resultados en {city}."

        institutions_to_create = []
        names_seen = set()
        
        for el in elements:
            tags = el.get('tags', {})
            name = tags.get('name') or tags.get('official_name')
            if not name or name.lower() in names_seen: continue
            
            names_seen.add(name.lower())
            
            institutions_to_create.append(
                Institution(
                    name=name,
                    city=city,
                    country=country,
                    institution_type=tags.get('amenity', 'school'),
                    discovery_source='osm',
                    mission_id=batch_uuid, 
                    is_active=True
                )
            )

        logger.info(f"‚è≥ [OSM RADAR] Limpiando datos y guardando {len(institutions_to_create)} leads en la Base de Datos...")

        # Inserci√≥n At√≥mica Bulk (O(n) optimizado)
        with transaction.atomic():
            Institution.objects.bulk_create(
                institutions_to_create, 
                ignore_conflicts=True, 
                batch_size=500
            )
        
        logger.info(f"üéØ [OSM RADAR] √âXITO TOTAL. Misi√≥n completada. La tabla web deber√≠a actualizarse ahora.")
        return {"mission_id": batch_uuid, "count": len(institutions_to_create)}

    except Exception as e:
        logger.error(f"‚ùå [OSM RADAR] Falla estructural: {str(e)}")
        raise 


# =========================================================
# MISI√ìN 2: RESOLUCI√ìN DE URLs (SERP CLUSTER)
# =========================================================
@shared_task(
    bind=True, 
    queue='default',
    soft_time_limit=900,
    time_limit=950
)
def task_run_serp_resolver(self, limit: int = 50):
    """Resuelve URLs oficiales para prospectos ciegos usando heur√≠stica SERP."""
    logger.info(f"üîç [SERP RESOLVER] Iniciando resoluci√≥n para {limit} objetivos.")
    try:
        engine = SERPResolverEngine(concurrency_limit=3)
        engine.resolve_missing_urls(limit=limit)
        return f"Resoluci√≥n completada (Lote de {limit})."
    except Exception as e:
        logger.error(f"‚ùå [SERP] Error en motor de b√∫squeda: {str(e)}")
        raise


# =========================================================
# MISI√ìN 3: BATCH GHOST SNIPER (ASYNCHRONOUS BATCHING)
# =========================================================
@shared_task(
    bind=True, 
    queue='scraping_queue',
    soft_time_limit=2400,
    time_limit=2500
)
def task_run_ghost_sniper(self, limit: int = 25, mission_id: Optional[str] = None):
    """
    Motor Forense Masivo por Lotes.
    Si se provee 'mission_id', prioriza ese lote espec√≠fico (Ideal para Ventana 3).
    """
    logger.info(f"üïµÔ∏è‚Äç‚ôÇÔ∏è [GHOST SNIPER] Desplegando ataque sobre lote (Misi√≥n: {mission_id})")
    
    # Filtro inteligente: prioriza por misi√≥n o por falta de escaneo
    query = Institution.objects.filter(website__isnull=False, is_active=True).exclude(website='')
    
    if mission_id:
        query = query.filter(mission_id=mission_id)
    else:
        query = query.filter(last_scored_at__isnull=True)

    qs = query[:limit]
    
    if not qs.exists():
        return "Misi√≥n abortada: Inbox Zero."

    targets = [
        {'id': inst.id, 'name': inst.name, 'url': inst.website, 'city': inst.city}
        for inst in qs
    ]

    try:
        # Orquestaci√≥n Playwright as√≠ncrona (Reutilizaci√≥n de navegador)
        asyncio.run(_orchestrate(targets))
        return f"Misi√≥n cumplida: {len(targets)} enriquecidos."
    except SoftTimeLimitExceeded:
        logger.warning("‚è≥ [GHOST SNIPER] Tiempo l√≠mite alcanzado. Lote procesado parcialmente.")
        return "Timeout parcial: Datos guardados hasta el punto de corte."
    except Exception as e:
        logger.error(f"‚ùå [GHOST SNIPER] Crash en el orquestador: {str(e)}")
        raise